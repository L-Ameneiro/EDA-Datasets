{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO  NO SUPERVISADO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las librerías que se utilizarán: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "import array\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan los datasets de puntajes asginados por usuarios de las plataformas\n",
    "\n",
    "#punt1 = pd.read_csv('..\\\\datasets\\\\puntajes\\\\1.csv')\n",
    "#punt2 = pd.read_csv('..\\\\datasets\\\\puntajes\\\\2.csv')\n",
    "#punt3 = pd.read_csv('..\\\\datasets\\\\puntajes\\\\3.csv')\n",
    "punt4 = pd.read_csv('..\\\\datasets\\\\puntajes\\\\4.csv')\n",
    "#punt5 = pd.read_csv('..\\\\datasets\\\\puntajes\\\\5.csv')\n",
    "#punt6 = pd.read_csv('..\\\\datasets\\\\puntajes\\\\6.csv')\n",
    "#punt7 = pd.read_csv('..\\\\datasets\\\\puntajes\\\\7.csv')\n",
    "#punt8 = pd.read_csv('..\\\\datasets\\\\puntajes\\\\8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se borra la columna timestamp porque no se utilizará\n",
    "punt4 = punt4.drop(columns = ['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500000 entries, 0 to 1499999\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count    Dtype  \n",
      "---  ------   --------------    -----  \n",
      " 0   userId   1500000 non-null  int64  \n",
      " 1   rating   1500000 non-null  float64\n",
      " 2   movieId  1500000 non-null  object \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 34.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Se verifica el tipo de dato de cada columna\n",
    "punt4. info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId     0\n",
       "rating     0\n",
       "movieId    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se verifica que no hayan valores nulos\n",
    "punt4.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se hace el filtrado de acuerdo a nuestro dataset para obtener las puntuaciones de sólamente las peliculas que se poseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importa el dataset final (CSV) y se visualiza\n",
    "peliculas5=pd.read_csv(r'..\\\\datasets\\\\peliculas_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el codigo de abajo no funciona\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza el filtrado con la función merge\n",
    "punt2 = pd.merge(punt4, peliculas5, left_on='movieId', right_on='show_id', how='inner')\n",
    "\n",
    "# Se Seleccionan las columnas 'userId', 'rating' y 'movieId'\n",
    "punt2 = punt4[['userId', 'rating', 'movieId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza el filtrado con la función merge\n",
    "punt2 = pd.merge(punt4, peliculas5, left_on='movieId', right_on='show_id', how='inner')\n",
    "\n",
    "# Se Seleccionan las columnas 'userId', 'rating' y 'movieId'\n",
    "punt2 = punt4[['userId', 'rating', 'movieId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una columna plataforma con \n",
    "def asignar_plataforma(movieId):\n",
    "    if 'a' in movieId:\n",
    "        return 'Amazon'\n",
    "    elif 'n' in movieId:\n",
    "        return 'Netflix'\n",
    "    elif 'd' in movieId:\n",
    "        return 'Disney'\n",
    "    elif 'h' in movieId:\n",
    "        return 'hulu'\n",
    "    \n",
    "punt2['plataforma'] = punt2['movieId'].apply(asignar_plataforma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "punt2 = punt2[(punt2['plataforma'] != 'Netflix') & (punt2['plataforma'] != 'Disney')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realizan códigos para la columna plataforma que posee variables cualitativas\n",
    "map_gender = {'Netflix': 1, 'Amazon': 2, 'Disney': 3}\n",
    "punt2['plataforma'] = punt2['plataforma'].replace(map_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan las letras de la columan movieId\n",
    "def eliminar_letras(texto):\n",
    "    return re.sub(r'[a-zA-Z]', '', texto)\n",
    "# Se Aplica la función a la columna 'movieId'\n",
    "punt2['movieId'] = punt2['movieId'].apply(eliminar_letras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>movieId</th>\n",
       "      <th>plataforma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3203</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5959</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4430</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6604</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2438</td>\n",
       "      <td>hulu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499995</th>\n",
       "      <td>61768</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1021</td>\n",
       "      <td>hulu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499996</th>\n",
       "      <td>61768</td>\n",
       "      <td>3.0</td>\n",
       "      <td>885</td>\n",
       "      <td>hulu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499997</th>\n",
       "      <td>61768</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4321</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499998</th>\n",
       "      <td>61768</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2422</td>\n",
       "      <td>hulu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499999</th>\n",
       "      <td>61768</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6170</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>831613 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  rating movieId plataforma\n",
       "0         46200     5.0    3203          2\n",
       "1         46200     1.0    5959          2\n",
       "2         46200     3.0    4430          2\n",
       "3         46200     4.0    6604          2\n",
       "5         46200     3.0    2438       hulu\n",
       "...         ...     ...     ...        ...\n",
       "1499995   61768     3.5    1021       hulu\n",
       "1499996   61768     3.0     885       hulu\n",
       "1499997   61768     4.0    4321          2\n",
       "1499998   61768     4.0    2422       hulu\n",
       "1499999   61768     3.5    6170          2\n",
       "\n",
       "[831613 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se guarda el dataset a csv\n",
    "punt2.to_csv(r'..\\datasets\\punt2.csv', index=False)\n",
    "punt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'hulu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Usuario\\Desktop\\data science\\ENTREGAS PELICULAS\\IngeniasDataScience\\notebooks\\MODELO NO SUPERVISADO.ipynb Celda 16\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Desktop/data%20science/ENTREGAS%20PELICULAS/IngeniasDataScience/notebooks/MODELO%20NO%20SUPERVISADO.ipynb#X66sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Desktop/data%20science/ENTREGAS%20PELICULAS/IngeniasDataScience/notebooks/MODELO%20NO%20SUPERVISADO.ipynb#X66sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Desktop/data%20science/ENTREGAS%20PELICULAS/IngeniasDataScience/notebooks/MODELO%20NO%20SUPERVISADO.ipynb#X66sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m scaler\u001b[39m.\u001b[39mfit(punt2)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Desktop/data%20science/ENTREGAS%20PELICULAS/IngeniasDataScience/notebooks/MODELO%20NO%20SUPERVISADO.ipynb#X66sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m punt2_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(punt2)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Desktop/data%20science/ENTREGAS%20PELICULAS/IngeniasDataScience/notebooks/MODELO%20NO%20SUPERVISADO.ipynb#X66sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 824\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:861\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m    860\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 861\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    862\u001b[0m     X,\n\u001b[0;32m    863\u001b[0m     accept_sparse\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    864\u001b[0m     dtype\u001b[39m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m    865\u001b[0m     force_all_finite\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    866\u001b[0m     reset\u001b[39m=\u001b[39mfirst_call,\n\u001b[0;32m    867\u001b[0m )\n\u001b[0;32m    868\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    870\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype, xp\u001b[39m=\u001b[39mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'hulu'"
     ]
    }
   ],
   "source": [
    "#Se escalan los datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(punt2)\n",
    "punt2_scaled = scaler.transform(punt2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se observa la distribución\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.countplot (x= \"rating\", data=punt2)\n",
    "plt.title(\"Puntaje\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza el método del codo para determinar la cantidad de clusters\n",
    "k=np. arange(1,11)\n",
    "lista_inercias = []\n",
    "for i in k:\n",
    "    kmeans = KMeans(n_clusters=i, random_state=0) \n",
    "# Instancia la clase KMeans\n",
    "    kmeans.fit(x)  \n",
    "# Ajusta el modelo KMeans a tus datos x\n",
    "    lista_inercias.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafica el método del codo\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(k, lista_inercias, marker='o', linestyle='-', color='c')\n",
    "plt.scatter(k, lista_inercias, c='r')\n",
    "plt.xlabel('Cantidad de clusters (k)')\n",
    "plt.ylabel('inercia media')\n",
    "plt.title('The Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se visualiza en otro tipo de gráfico\n",
    "plt.plot(k, marker='o', linestyle='-', color='b')\n",
    "plt.axvline(3, 0, 1, color='red')\n",
    "plt.xlabel('Cantidad de clusters (k)')\n",
    "plt.ylabel('Puntaje del modelo')\n",
    "plt.title('Puntaje del modelo para determinar el número óptimo de clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cantidad de cluster a utilizar son 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la cantidad de clusters\n",
    "num_clusters=3\n",
    "\n",
    "# Se crea una instancia del modelo K-Means\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "# Se ajusta el modelo a tus datos\n",
    "kmeans.fit(x)\n",
    "kmeans.fit(x)\n",
    "kmeans\n",
    "# Se obtiene las etiquetas de clúster para cada punto de datos\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Se obtiene las coordenadas de los centroides de los clústeres\n",
    "centroids = kmeans.cluster_centers_\n",
    "centroids = kmeans\n",
    "print (centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un gráfico de dispersión para visualizar la distribución de los clústeres\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='rating', y='userId', hue='cluster', data=x, palette='viridis')\n",
    "plt.title('Distribución de Clústeres')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f87a3a2",
   "metadata": {},
   "source": [
    "# Se importan las librerías que se utilizarán: \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "import array\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se realiza el filtrado con la función merge\n",
    "punt2 = pd.merge(punt1, peliculas5, left_on='movieId', right_on='show_id', how='inner')\n",
    "\n",
    "# Se Seleccionan las columnas 'userId', 'rating' y 'movieId'\n",
    "punt2 = punt2[['userId', 'rating', 'movieId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una columna plataforma con \n",
    "def asignar_plataforma(movieId):\n",
    "    if 'a' in movieId:\n",
    "        return 'Amazon'\n",
    "    elif 'n' in movieId:\n",
    "        return 'Netflix'\n",
    "    elif 'd' in movieId:\n",
    "        return 'Disney'\n",
    "    elif 'h' in movieId:\n",
    "        return 'hulu'\n",
    "    \n",
    "punt2['plataforma'] = punt2['movieId'].apply(asignar_plataforma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f82911",
   "metadata": {},
   "outputs": [],
   "source": [
    "punt2 = punt2[(punt2['plataforma'] != 'Netflix') & (punt2['plataforma'] != 'Disney')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4b6538",
   "metadata": {},
   "source": [
    "# Se realizan códigos para la columna plataforma que posee variables cualitativas\n",
    "map_gender = {'Netflix': 1, 'Amazon': 2, 'Disney': 3}\n",
    "punt2['plataforma'] = punt2['plataforma'].replace(map_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se eliminan las letras de la columan movieId\n",
    "def eliminar_letras(texto):\n",
    "    return re.sub(r'[a-zA-Z]', '', texto)\n",
    "# Se Aplica la función a la columna 'movieId'\n",
    "punt2['movieId'] = punt2['movieId'].apply(eliminar_letras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se guarda el dataset a csv\n",
    "punt2.to_csv(r'..\\datasets\\punt2.csv', index=False)\n",
    "punt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89efd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se escalan los datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(punt2)\n",
    "punt2_scaled = scaler.transform(punt2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se convierte la matriz numpy en un DataFrame\n",
    "punt2_scaled_df = pd.DataFrame(punt2_scaled, columns=punt2.columns)\n",
    "# Se seleccionan las variables\n",
    "x = punt2_scaled_df.iloc[:, [1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se observa la distribución\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.countplot (x= \"rating\", data=punt2)\n",
    "plt.title(\"Puntaje\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7171cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza el método del codo para determinar la cantidad de clusters\n",
    "k=np. arange(1,11)\n",
    "lista_inercias = []\n",
    "for i in k:\n",
    "    kmeans = KMeans(n_clusters=i, random_state=0) \n",
    "# Instancia la clase KMeans\n",
    "    kmeans.fit(x)  \n",
    "# Ajusta el modelo KMeans a tus datos x\n",
    "    lista_inercias.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que la distribución de las muestras en 3 clusters no es igual en cada grupo. Se analizará posteriormente la distribución en dos clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se observan las coordenandas de los centroides\n",
    "centroids3 =kmeansmodel3.cluster_centers_\n",
    "print(centroids3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N° de clusters:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se instancia el modelo con el numero de clusters \n",
    "kmeansmodel3 = KMeans(n_clusters=2, random_state=0)\n",
    "kmeansmodel3.fit(p1_scal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiquetas de los clusters\n",
    "etiquetas_2 = kmeansmodel3.labels_\n",
    "np.unique(etiquetas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c23534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace la predicción:\n",
    "y_means2=kmeansmodel3.fit_predict(p1_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6096714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se verifica la cantidad de observaciones (2 clusters)\n",
    "cluster_counts = np.bincount(y_means2)\n",
    "cluster_labels = list(range(len(cluster_counts)))\n",
    "colors = ['lightcoral', 'mediumturquoise', 'plum']\n",
    "plt.bar(cluster_labels, cluster_counts, color=colors)\n",
    "plt.title('Cantidad de muestras por cluster')\n",
    "plt.xlabel('Grupo')\n",
    "plt.ylabel('Cantidad de Observaciones')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093ed5e",
   "metadata": {},
   "source": [
    "Se puede observar que con dos clusters, la cantidad de muestras es bastante equitativa para cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec80b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se observan las coordenandas de los centroides\n",
    "centroids2 =kmeansmodel2.cluster_centers_\n",
    "print(centroids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a115bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica como performan\n",
    "p1 = [x_subset]\n",
    "df = pd.DataFrame(p1, columns=['X', 'Y'])\n",
    "df['Cluster'] = etiquetas_1\n",
    "sns.scatterplot(x='X', y='Y', hue='Cluster', p1=df, palette='pastel2')\n",
    "plt.scatter(centroides[:, 0], centroides[:, 1], c='green', marker='x', s=200, label='Centroids1')\n",
    "plt.title('Distribución de Clusters y Centroides')\n",
    "plt.xlabel('Eje X')\n",
    "plt.ylabel('Eje Y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se evalua con la suma de los cuadrados de las distancias (SSD)\n",
    "SSD= kmeansmodel2.inertia_\n",
    "print( \"SSD: \",SSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85fe60b",
   "metadata": {},
   "source": [
    "cuanto debe dar?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405991ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza la evaluación con silhoutte\n",
    "sil = []\n",
    "kmax = 10\n",
    "\n",
    "# dissimilarity would not be defined for a single cluster, thus, minimum number of clusters should be 3\n",
    "for k in range(2, kmax+1):\n",
    "    kmeans = KMeans(n_clusters=k).fit(p1_scal)\n",
    "    labels = kmeans.labels_\n",
    "    sil.append(silhouette_score(p1_scal, labels, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6baa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafica\n",
    "plt.plot(range(2,11),sil, c=\"#c51b7d\")\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.title('Metodo Silhouette', size=14)\n",
    "plt.xlabel('Numero de clusters', size=12)\n",
    "plt.ylabel('Puntaje de Silhouette', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se concatenan los datasets\n",
    "#punt = pd.concat([punt1, punt2, punt3, punt4, punt5, punt6, punt7, punt8], axis=0, ignore_index=True)\n",
    "#punt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07dc6f1",
   "metadata": {},
   "source": [
    "Se debe considerar el coeficiente de silhoutte más cercano a 1, por lo que se reagruparán en 2 cluster. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
